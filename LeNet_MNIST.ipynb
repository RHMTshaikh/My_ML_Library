{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2230ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Device Configuration ---\n",
    "# Use CUDA (GPU) if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 2. Hyperparameters ---\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001 # A common learning rate for Adam optimizer\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "# You can increase this for better performance\n",
    "\n",
    "# --- 3. Data Loading and Preprocessing ---\n",
    "# Define transformations to apply to the MNIST images\n",
    "# ToTensor() converts PIL Image to PyTorch Tensor and scales pixel values to [0, 1]\n",
    "# Normalize() normalizes the pixel values (mean=0.1307, std=0.3081 are standard for MNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # Mean and Std Dev for MNIST\n",
    "])\n",
    "\"\"\"\n",
    "Preserves Spatial Relationships: It maintains the relative differences between adjacent pixels, \n",
    "which is crucial for convolutional networks to learn spatial features. If you normalized each \n",
    "pixel independently, you might distort these relationships.\n",
    "\n",
    "Loss of Positional Invariance (partially): A core strength of CNNs is their ability to learn \n",
    "filters that are useful regardless of where in the image a feature appears (translational invariance).\n",
    "If you normalize each pixel position differently, you make that position more unique, \n",
    "potentially hindering the network's ability to learn generalizable features.\n",
    "\"\"\"\n",
    "\n",
    "# Download and load the training dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Download and load the test dataset\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training data samples: {len(train_dataset)}\")\n",
    "print(f\"Test data samples: {len(test_dataset)}\")\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")\n",
    "\n",
    "# --- 4. Model Definition (LeNet-like Architecture) ---\n",
    "# This model matches the layer progression you described:\n",
    "# Conv -> Pool -> Conv -> Pool -> Conv -> Flatten -> Dense -> Dense\n",
    "class LeNetLike(nn.Module):\n",
    "    def __init__(self):\n",
    "        # super(LeNetLike, self).__init__()\n",
    "        super().__init__()\n",
    "        \n",
    "        # Layer 1: Convolutional Layer\n",
    "        # Input: (N, 1, 28, 28) -> Output: (N, 6, 24, 24)\n",
    "        # (28 - 5)/1 + 1 = 24\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "        self.tanh = nn.Tanh() # Activation function as per your model definition\n",
    "\n",
    "        # Layer 2: Pooling Layer (Average Pooling)\n",
    "        # Input: (N, 6, 24, 24) -> Output: (N, 6, 12, 12)\n",
    "        # 24 / 2 = 12\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # Layer 3: Convolutional Layer\n",
    "        # Input: (N, 6, 12, 12) -> Output: (N, 16, 8, 8)\n",
    "        # (12 - 5)/1 + 1 = 8\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        # self.tanh2 = nn.Tanh() # Activation function\n",
    "\n",
    "        # Layer 4: Pooling Layer (Average Pooling)\n",
    "        # Input: (N, 16, 8, 8) -> Output: (N, 16, 4, 4)\n",
    "        # 8 / 2 = 4\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # Layer 5: Convolutional Layer (often called C5 in LeNet)\n",
    "        # Input: (N, 16, 4, 4) -> Output: (N, 120, 1, 1)\n",
    "        # (4 - 4)/1 + 1 = 1\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=4, stride=1, padding=0)\n",
    "        # self.tanh3 = nn.Tanh() # Activation function\n",
    "\n",
    "        # Flatten Layer: Converts 3D feature maps to 1D vector\n",
    "        # Input: (N, 120, 1, 1) -> Output: (N, 120)\n",
    "        # nn.Flatten is simpler than manual reshape\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Layer 6: Dense (Linear) Layer\n",
    "        # Input: (N, 120) -> Output: (N, 84)\n",
    "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
    "        # self.tanh4 = nn.Tanh() # Activation function\n",
    "\n",
    "        # Layer 7: Dense (Linear) Layer (Output Layer)\n",
    "        # Input: (N, 84) -> Output: (N, 10) (10 classes for MNIST digits)\n",
    "        # No activation here, as CrossEntropyLoss expects raw logits.\n",
    "        self.fc2 = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through each layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.tanh(x)\n",
    "        \n",
    "        x = self.flatten(x) # Flatten the feature maps into a vector\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.tanh(x)\n",
    "\n",
    "        x = self.fc2(x) # Output logits\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model and move it to the configured device (CPU/GPU)\n",
    "model = LeNetLike().to(device)\n",
    "# --- 5. Loss Function and Optimizer ---\n",
    "# CrossEntropyLoss combines nn.LogSoftmax and nn.NLLLoss in one\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Adam optimizer is a good general-purpose optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# --- 6. Training Loop ---\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train() # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Move data and targets to the device (CPU/GPU)\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(data)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Zero the gradients of the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() # Accumulate loss\n",
    "        \n",
    "        if (batch_idx + 1) % 100 == 0: # Print every 100 batches\n",
    "            avg_batch_loss = running_loss / (batch_idx + 1)\n",
    "            print(f\"Epoch: {epoch+1}/{NUM_EPOCHS}, Batch: {batch_idx+1}/{len(train_loader)}, Loss: {avg_batch_loss:.4f}\")\n",
    "        \n",
    "    # Calculate average training loss for the epoch\n",
    "    epoch_avg_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_avg_loss)\n",
    "    print(f\"Epoch {epoch+1} finished. Average Training Loss: {epoch_avg_loss:.4f}\")\n",
    "\n",
    "    # --- 7. Evaluation after each epoch ---\n",
    "    model.eval() # Set the model to evaluation mode (disables dropout, batchnorm updates)\n",
    "    test_running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Disable gradient calculation during evaluation for efficiency\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_running_loss += loss.item()\n",
    "\n",
    "            # Get predicted class (the index of the max log-probability)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += targets.size(0)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "    avg_test_loss = test_running_loss / len(test_loader)\n",
    "    accuracy = (correct_predictions / total_samples) * 100\n",
    "    test_losses.append(avg_test_loss)\n",
    "    test_accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Evaluation - Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.2f}%\\n\")\n",
    "\n",
    "print(\"--- Training Complete ---\")\n",
    "\n",
    "# --- 8. Plotting Training and Test Loss/Accuracy ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), test_losses, label='Test Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), test_accuracies, label='Test Accuracy', color='green')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 9. Test with a few samples (Optional) ---\n",
    "print(\"\\n--- Testing with a few samples ---\")\n",
    "model.eval()\n",
    "data_iter = iter(test_loader)\n",
    "images, labels = next(data_iter) # Get a batch\n",
    "\n",
    "# Display some images and their predictions\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 3))\n",
    "for i in range(5):\n",
    "    img = images[i].to(device)\n",
    "    true_label = labels[i].item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img.unsqueeze(0)) # Add batch dimension for single image\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        predicted_label = predicted.item()\n",
    "\n",
    "    # Denormalize image for display\n",
    "    # img_display = img.cpu().squeeze().numpy() * 0.3081 + 0.1307 # if normalized\n",
    "    img_display = img.cpu().squeeze().numpy() # If not denormalizing, assuming it's okay for visual\n",
    "\n",
    "    axes[i].imshow(img_display, cmap='gray')\n",
    "    axes[i].set_title(f\"True: {true_label}\\nPred: {predicted_label}\", color='green' if true_label == predicted_label else 'red')\n",
    "    axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ad6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "import platform\n",
    "import sklearn.metrics as skmetrics\n",
    "import ast\n",
    "\n",
    "# --- Start of Script Execution Timestamp ---\n",
    "current_time_str = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "EXPERIMENT_ID = f\"LeNet_MNIST_Run_{current_time_str}\"\n",
    "LOG_DIR = \"experiment_logs\"\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "LOG_FILE_PATH = os.path.join(LOG_DIR, f\"{EXPERIMENT_ID}.json\")\n",
    "\n",
    "experiment_log = defaultdict(dict)\n",
    "experiment_log[\"experiment_id\"] = EXPERIMENT_ID\n",
    "experiment_log[\"date_time_started\"] = datetime.datetime.now().isoformat()\n",
    "experiment_log[\"description\"] = \"Baseline LeNet-like model on MNIST with default Adam parameters and added logging.\\\n",
    "    With no normalisation of data.\"\n",
    "\n",
    "# --- 1. Device Configuration ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "experiment_log[\"hardware\"][\"device\"] = str(device)\n",
    "if torch.cuda.is_available():\n",
    "    experiment_log[\"hardware\"][\"gpu_name\"] = torch.cuda.get_device_name(0)\n",
    "    experiment_log[\"hardware\"][\"gpu_vram_gb\"] = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "experiment_log[\"hardware\"][\"cpu_cores\"] = os.cpu_count()\n",
    "\n",
    "# Add software environment details\n",
    "experiment_log[\"software_env\"][\"python_version\"] = platform.python_version()\n",
    "experiment_log[\"software_env\"][\"pytorch_version\"] = torch.__version__\n",
    "experiment_log[\"software_env\"][\"torchvision_version\"] = torchvision.__version__\n",
    "if torch.cuda.is_available():\n",
    "    experiment_log[\"software_env\"][\"cuda_version\"] = torch.version.cuda\n",
    "    experiment_log[\"software_env\"][\"cudnn_version\"] = torch.backends.cudnn.version()\n",
    "\n",
    "\n",
    "# --- 2. Hyperparameters ---\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "experiment_log[\"hyperparameters\"][\"batch_size\"] = BATCH_SIZE\n",
    "experiment_log[\"hyperparameters\"][\"learning_rate\"] = LEARNING_RATE\n",
    "experiment_log[\"hyperparameters\"][\"num_epochs\"] = NUM_EPOCHS\n",
    "# experiment_log[\"hyperparameters\"][\"optimizer_name\"] = \"Adam\"\n",
    "# experiment_log[\"hyperparameters\"][\"loss_function_name\"] = \"CrossEntropyLoss\"\n",
    "\n",
    "mean = 0.1307\n",
    "std = 0.3081\n",
    "# --- 3. Data Loading and Preprocessing ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((mean,), (std,)) # Normalization disabled as per original request\n",
    "])\n",
    "\n",
    "experiment_log[\"dataset\"][\"name\"] = \"MNIST\"\n",
    "experiment_log[\"dataset\"][\"transformations\"] = [str(t) for t in transform.transforms]\n",
    "# experiment_log[\"dataset\"][\"normalization_mean\"] = [mean]\n",
    "# experiment_log[\"dataset\"][\"normalization_std\"] = [std]\n",
    "\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "# FIX: Corrected the DataLoader creation for test_loader\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "experiment_log[\"dataset\"][\"train_samples\"] = len(train_dataset)\n",
    "experiment_log[\"dataset\"][\"test_samples\"] = len(test_dataset)\n",
    "experiment_log[\"dataset\"][\"num_train_batches\"] = len(train_loader)\n",
    "experiment_log[\"dataset\"][\"num_test_batches\"] = len(test_loader)\n",
    "\n",
    "train_labels = np.array(train_dataset.targets)\n",
    "unique, counts = np.unique(train_labels, return_counts=True)\n",
    "experiment_log[\"dataset\"][\"class_distribution_train\"] = {str(u): int(c) for u, c in zip(unique, counts)}\n",
    "\n",
    "\n",
    "print(f\"Training data samples: {len(train_dataset)}\")\n",
    "print(f\"Test data samples: {len(test_dataset)}\")\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")\n",
    "\n",
    "# --- 4. Model Definition (LeNet-like Architecture) ---\n",
    "class LeNetLike(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define a single Tanh activation layer for reuse\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=4, stride=1, padding=0)\n",
    "        \n",
    "        self.flatten_op = nn.Flatten() # Renamed to avoid potential conflict with method names\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.fc2 = nn.Linear(in_features=84, out_features=10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation(x) # Reusing the single tanh instance\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation(x) # Reusing the single tanh instance\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.activation(x) # Reusing the single tanh instance\n",
    "        \n",
    "        x = self.flatten_op(x) # Use the named flatten module\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x) # Reusing the single tanh instance\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = LeNetLike().to(device)\n",
    "\n",
    "# --- Global flag and function for dynamic model architecture logging ---\n",
    "_model_architecture_traced = False\n",
    "\n",
    "def trace_model_architecture(model_instance, dummy_input_for_trace, experiment_log_dict):\n",
    "    \"\"\"\n",
    "    Traces the model's forward pass once using hooks to log layer details and output shapes.\n",
    "    \"\"\"\n",
    "    model_trace_results = []\n",
    "    hooks = []\n",
    "    \n",
    "    # Counter for uniquely naming repeated activation layers (e.g., relu_1, relu_2)\n",
    "    activation_counters = defaultdict(int)\n",
    "    \n",
    "    # Create a mapping from module instance to its \"user-defined\" name from named_children()\n",
    "    # This will give us names like 'conv1', 'relu', 'pool1' etc.\n",
    "    named_children_map = {module: name for name, module in model_instance.named_children()}\n",
    "    \n",
    "    def forward_hook_fn(module, input, output):\n",
    "        # Skip the top-level model container itself or empty Sequential (if any)\n",
    "        if module == model_instance or (isinstance(module, nn.Sequential) and not list(module.children())):\n",
    "            return\n",
    "\n",
    "        layer_info = {\n",
    "            \"type\": module.__class__.__name__,\n",
    "        }\n",
    "        \n",
    "        # Determine the layer's name based on its type and whether it's a named child\n",
    "        if isinstance(module, (nn.ReLU, nn.Tanh, nn.Sigmoid)):\n",
    "            # For activations, always use a counter to differentiate multiple uses\n",
    "            activation_counters[module.__class__.__name__] += 1\n",
    "            layer_info[\"name\"] = f\"{module.__class__.__name__.lower()}_{activation_counters[module.__class__.__name__]}\"\n",
    "            layer_info[\"activation\"] = module.__class__.__name__ # Add activation field\n",
    "        elif module in named_children_map:\n",
    "            # For other modules that are direct named children, use their defined name\n",
    "            layer_info[\"name\"] = named_children_map[module]\n",
    "        else:\n",
    "            # Fallback for other modules (e.g., if inside an nn.Sequential not directly named)\n",
    "            layer_info[\"name\"] = module.__class__.__name__.lower() # Use lowercase type as fallback name\n",
    "\n",
    "        # Input shape (take the first element if input is a tuple, otherwise it's the tensor itself)\n",
    "        input_tensor_for_shape = input[0] if isinstance(input, tuple) else input\n",
    "        layer_info[\"input_shape\"] = str(list(input_tensor_for_shape.shape))\n",
    "\n",
    "        # Add specific parameters based on module type\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            layer_info.update({\n",
    "                \"in_channels\": module.in_channels,\n",
    "                \"out_channels\": module.out_channels,\n",
    "                \"kernel_size\": str(module.kernel_size),\n",
    "                \"stride\": str(module.stride),\n",
    "                \"padding\": str(module.padding)\n",
    "            })\n",
    "        elif isinstance(module, (nn.Linear)):\n",
    "            layer_info.update({\n",
    "                \"in_features\": module.in_features,\n",
    "                \"out_features\": module.out_features\n",
    "            })\n",
    "        elif isinstance(module, (nn.AvgPool2d, nn.MaxPool2d)):\n",
    "            layer_info.update({\n",
    "                \"kernel_size\": str(module.kernel_size),\n",
    "                \"stride\": str(module.stride),\n",
    "                \"padding\": str(module.padding)\n",
    "            })\n",
    "        elif isinstance(module, nn.Flatten):\n",
    "            pass # No extra parameters needed, type is enough\n",
    "\n",
    "        layer_info[\"output_shape\"] = str(list(output.shape))\n",
    "        model_trace_results.append(layer_info)\n",
    "\n",
    "    # Register hooks to all submodules (recursively using named_modules)\n",
    "    # The order of execution in forward pass will trigger hooks in that order.\n",
    "    for _, module in model_instance.named_modules():\n",
    "        # Skip the top-level model module itself, as it's just a container.\n",
    "        # Also skip modules that are just containers with no parameters or specific ops (e.g., empty nn.Sequential)\n",
    "        if module == model_instance or (not list(module.children()) and not list(module.parameters()) and not isinstance(module, (nn.ReLU, nn.Tanh, nn.Sigmoid, nn.Flatten))):\n",
    "            continue\n",
    "        \n",
    "        hook = module.register_forward_hook(forward_hook_fn)\n",
    "        hooks.append(hook)\n",
    "\n",
    "    # Perform a dummy forward pass to trigger hooks\n",
    "    with torch.no_grad():\n",
    "        _ = model_instance(dummy_input_for_trace)\n",
    "\n",
    "    # Remove hooks after tracing to avoid performance overhead during training\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "    \n",
    "    # Populate the experiment log with the traced results\n",
    "    experiment_log_dict[\"model_architecture\"][\"layers\"] = model_trace_results\n",
    "\n",
    "\n",
    "# --- Dynamic Model Architecture Logging using Hooks (Execution) ---\n",
    "experiment_log[\"model_architecture\"][\"name\"] = model.__class__.__name__\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "experiment_log[\"model_architecture\"][\"total_trainable_parameters\"] = total_params\n",
    "\n",
    "if not _model_architecture_traced:\n",
    "    dummy_input_for_trace = torch.randn(1, 1, 28, 28).to(device)\n",
    "    trace_model_architecture(model, dummy_input_for_trace, experiment_log)\n",
    "    _model_architecture_traced = True # Set the flag to True after tracing\n",
    "\n",
    "print(f\"Total trainable parameters: {experiment_log['model_architecture']['total_trainable_parameters']}\")\n",
    "\n",
    "\n",
    "# --- 5. Loss Function and Optimizer ---\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "experiment_log[\"hyperparameters\"][\"optimizer_name\"] = optimizer.__class__.__name__\n",
    "optimizer_params_cleaned = {}\n",
    "for k, v in optimizer.defaults.items():\n",
    "    if isinstance(v, (torch.Tensor, np.ndarray)):\n",
    "        optimizer_params_cleaned[k] = v.item() if v.numel() == 1 else v.tolist()\n",
    "    else:\n",
    "        optimizer_params_cleaned[k] = v\n",
    "experiment_log[\"hyperparameters\"][\"optimizer_params\"] = optimizer_params_cleaned\n",
    "experiment_log[\"hyperparameters\"][\"loss_function_name\"] = criterion.__class__.__name__\n",
    "\n",
    "\n",
    "# --- 6. Training Loop ---\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "experiment_log[\"training_results\"][\"train_losses_per_epoch\"] = []\n",
    "experiment_log[\"training_results\"][\"test_losses_per_epoch\"] = []\n",
    "experiment_log[\"training_results\"][\"test_accuracies_per_epoch\"] = []\n",
    "experiment_log[\"training_results\"][\"test_precisions_macro_per_epoch\"] = []\n",
    "experiment_log[\"training_results\"][\"test_recalls_macro_per_epoch\"] = []\n",
    "experiment_log[\"training_results\"][\"test_f1_scores_macro_per_epoch\"] = []\n",
    "experiment_log[\"training_results\"][\"test_roc_auc_macro_per_epoch\"] = []\n",
    "\n",
    "\n",
    "best_test_accuracy = -1.0\n",
    "best_epoch = -1\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "total_training_start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            avg_batch_loss = running_loss / (batch_idx + 1)\n",
    "            print(f\"Epoch: {epoch+1}/{NUM_EPOCHS}, Batch: {batch_idx+1}/{len(train_loader)}, Loss: {avg_batch_loss:.4f}\")\n",
    "        \n",
    "    epoch_avg_loss = running_loss / len(train_loader)\n",
    "    experiment_log[\"training_results\"][\"train_losses_per_epoch\"].append(epoch_avg_loss)\n",
    "    \n",
    "    # --- 7. Evaluation after each epoch ---\n",
    "    model.eval()\n",
    "    test_running_loss = 0.0\n",
    "    \n",
    "    epoch_true_labels = []\n",
    "    epoch_pred_labels = []\n",
    "    epoch_pred_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            epoch_true_labels.extend(targets.cpu().numpy())\n",
    "            epoch_pred_labels.extend(predicted.cpu().numpy())\n",
    "            epoch_pred_scores.extend(outputs.cpu().numpy())\n",
    "\n",
    "    avg_test_loss = test_running_loss / len(test_loader)\n",
    "    accuracy = float(skmetrics.accuracy_score(epoch_true_labels, epoch_pred_labels) * 100)\n",
    "    \n",
    "    experiment_log[\"training_results\"][\"test_losses_per_epoch\"].append(avg_test_loss)\n",
    "    experiment_log[\"training_results\"][\"test_accuracies_per_epoch\"].append(accuracy)\n",
    "\n",
    "    precision, recall, f1, _ = skmetrics.precision_recall_fscore_support(\n",
    "        epoch_true_labels, epoch_pred_labels, average='macro', zero_division=0\n",
    "    )\n",
    "    experiment_log[\"training_results\"][\"test_precisions_macro_per_epoch\"].append(float(precision))\n",
    "    experiment_log[\"training_results\"][\"test_recalls_macro_per_epoch\"].append(float(recall))\n",
    "    experiment_log[\"training_results\"][\"test_f1_scores_macro_per_epoch\"].append(float(f1))\n",
    "\n",
    "    try:\n",
    "        roc_auc = float(skmetrics.roc_auc_score(epoch_true_labels, epoch_pred_scores, multi_class='ovr', average='macro'))\n",
    "    except ValueError as e:\n",
    "        roc_auc = None\n",
    "        print(f\"Warning: Could not compute ROC AUC for epoch {epoch+1}: {e}\")\n",
    "    experiment_log[\"training_results\"][\"test_roc_auc_macro_per_epoch\"].append(roc_auc)\n",
    "\n",
    "\n",
    "    # Track best model based on test accuracy\n",
    "    if accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = accuracy\n",
    "        best_epoch = epoch + 1\n",
    "        best_test_loss = avg_test_loss\n",
    "        \n",
    "        # Store detailed metrics for the best epoch\n",
    "        experiment_log[\"final_evaluation_metrics\"][\"best_epoch_details\"] = {\n",
    "            \"epoch_number\": best_epoch,\n",
    "            \"test_accuracy\": float(best_test_accuracy),\n",
    "            \"test_loss\": float(best_test_loss),\n",
    "            \"precision_macro_avg\": float(precision),\n",
    "            \"recall_macro_avg\": float(f1),\n",
    "            \"f1_score_macro_avg\": float(f1),\n",
    "            \"roc_auc_macro_avg\": roc_auc,\n",
    "            \"confusion_matrix_at_best_epoch\": str(skmetrics.confusion_matrix(epoch_true_labels, epoch_pred_labels).tolist())\n",
    "        }\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_time = epoch_end_time - epoch_start_time\n",
    "\n",
    "    print(f\"Epoch {epoch+1} finished. Avg Training Loss: {epoch_avg_loss:.4f}, Test Loss: {avg_test_loss:.4f}, Test Acc: {accuracy:.2f}%, Time: {epoch_time:.2f}s\\n\")\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "total_training_end_time = time.time()\n",
    "total_training_time = total_training_end_time - total_training_start_time\n",
    "\n",
    "experiment_log[\"training_results\"][\"total_training_time_seconds\"] = total_training_time\n",
    "experiment_log[\"training_results\"][\"avg_time_per_epoch_seconds\"] = total_training_time / NUM_EPOCHS\n",
    "\n",
    "\n",
    "print(\"--- Training Complete ---\")\n",
    "print(f\"Total training duration: {total_training_time:.2f} seconds\")\n",
    "\n",
    "# --- Final Metrics after training ---\n",
    "model.eval()\n",
    "final_true_labels = []\n",
    "final_pred_labels = []\n",
    "final_pred_scores = []\n",
    "final_images = [] # Store images to display wrong predictions\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        data_cpu = data.cpu() # Keep on CPU for numpy conversion later\n",
    "        targets_cpu = targets.cpu() # Keep on CPU for numpy conversion later\n",
    "\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        final_true_labels.extend(targets_cpu.numpy())\n",
    "        final_pred_labels.extend(predicted.cpu().numpy())\n",
    "        final_pred_scores.extend(outputs.cpu().numpy())\n",
    "        final_images.append(data_cpu) # Store the images\n",
    "\n",
    "final_accuracy = float(skmetrics.accuracy_score(final_true_labels, final_pred_labels) * 100)\n",
    "final_precision, final_recall, final_f1, _ = skmetrics.precision_recall_fscore_support(\n",
    "    final_true_labels, final_pred_labels, average='macro', zero_division=0\n",
    ")\n",
    "final_precision = float(final_precision)\n",
    "final_recall = float(final_recall)\n",
    "final_f1 = float(final_f1)\n",
    "\n",
    "try:\n",
    "    final_roc_auc = float(skmetrics.roc_auc_score(final_true_labels, final_pred_scores, multi_class='ovr', average='macro'))\n",
    "except ValueError:\n",
    "    final_roc_auc = None\n",
    "final_cm = str(skmetrics.confusion_matrix(final_true_labels, final_pred_labels).tolist())\n",
    "\n",
    "experiment_log[\"final_evaluation_metrics\"][\"overall_accuracy_last_epoch\"] = final_accuracy\n",
    "experiment_log[\"final_evaluation_metrics\"][\"confusion_matrix_last_epoch\"] = final_cm\n",
    "experiment_log[\"final_evaluation_metrics\"][\"precision_macro_avg_last_epoch\"] = final_precision\n",
    "experiment_log[\"final_evaluation_metrics\"][\"recall_macro_avg_last_epoch\"] = final_recall\n",
    "experiment_log[\"final_evaluation_metrics\"][\"f1_score_macro_avg_last_epoch\"] = final_f1\n",
    "experiment_log[\"final_evaluation_metrics\"][\"roc_auc_macro_avg_last_epoch\"] = final_roc_auc\n",
    "\n",
    "precision_per_class, recall_per_class, f1_per_class, _ = skmetrics.precision_recall_fscore_support(\n",
    "    final_true_labels, final_pred_labels, average=None, zero_division=0\n",
    ")\n",
    "per_class_metrics = {}\n",
    "for i in range(len(unique)):\n",
    "    per_class_metrics[str(i)] = {\n",
    "        \"precision\": float(precision_per_class[i]),\n",
    "        \"recall\": float(recall_per_class[i]),\n",
    "        \"f1_score\": float(f1_per_class[i])\n",
    "    }\n",
    "experiment_log[\"final_evaluation_metrics\"][\"per_class_metrics_last_epoch\"] = per_class_metrics\n",
    "\n",
    "\n",
    "experiment_log[\"notes_observations\"] = \"Initial run of LeNet-like model. Achieved good accuracy. Consider more epochs or data augmentation next.\"\n",
    "\n",
    "# --- Save the experiment log to a JSON file ---\n",
    "print(f\"\\nSaving experiment log to {LOG_FILE_PATH}\")\n",
    "with open(LOG_FILE_PATH, 'w') as f:\n",
    "    for key in [\"train_losses_per_epoch\", \"test_losses_per_epoch\",\n",
    "                \"test_accuracies_per_epoch\", \"test_precisions_macro_per_epoch\",\n",
    "                \"test_recalls_macro_per_epoch\", \"test_f1_scores_macro_per_epoch\",\n",
    "                \"test_roc_auc_macro_per_epoch\"]:\n",
    "        if key in experiment_log[\"training_results\"] and isinstance(experiment_log[\"training_results\"][key], list):\n",
    "            # Convert list to string representation for JSON compatibility\n",
    "            experiment_log[\"training_results\"][key] = str(experiment_log[\"training_results\"][key])\n",
    "            \n",
    "    json.dump(experiment_log, f, indent=4)\n",
    "\n",
    "# --- 8. Plotting Training and Test Loss/Accuracy ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "# Use ast.literal_eval to convert string back to list for plotting\n",
    "train_losses_plot = ast.literal_eval(experiment_log[\"training_results\"][\"train_losses_per_epoch\"])\n",
    "test_losses_plot = ast.literal_eval(experiment_log[\"training_results\"][\"test_losses_per_epoch\"])\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_losses_plot, label='Training Loss')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), test_losses_plot, label='Test Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "test_accuracies_plot = ast.literal_eval(experiment_log[\"training_results\"][\"test_accuracies_per_epoch\"])\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), test_accuracies_plot, label='Test Accuracy', color='green')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 9. Test with a few random samples (Optional) ---\n",
    "print(\"\\n--- Testing with a few random samples ---\")\n",
    "model.eval()\n",
    "data_iter = iter(test_loader)\n",
    "images, labels = next(data_iter) # Get the first batch for display\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 3))\n",
    "for i in range(5):\n",
    "    img = images[i].to(device)\n",
    "    true_label = labels[i].item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img.unsqueeze(0))\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        predicted_label = predicted.item()\n",
    "\n",
    "    img_display = img.cpu().squeeze().numpy()\n",
    "\n",
    "    axes[i].imshow(img_display, cmap='gray')\n",
    "    axes[i].set_title(f\"True: {true_label}\\nPred: {predicted_label}\", color='green' if true_label == predicted_label else 'red')\n",
    "    axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- 10. Display Wrong Predictions ---\n",
    "print(\"\\n--- Displaying Wrong Predictions (up to 20 samples) ---\")\n",
    "# Flatten the list of batches into single tensors for easier indexing\n",
    "all_test_images = torch.cat(final_images, dim=0)\n",
    "\n",
    "wrong_indices = [i for i, (true, pred) in enumerate(zip(final_true_labels, final_pred_labels)) if true != pred]\n",
    "\n",
    "if not wrong_indices:\n",
    "    print(\"No wrong predictions found! Model achieved 100% accuracy.\")\n",
    "else:\n",
    "    num_wrong_to_show = max(len(wrong_indices), 20) # Show up to 20 wrong predictions\n",
    "    \n",
    "    # Calculate grid dimensions: try to make it somewhat square-like\n",
    "    # For 20, 4 rows x 5 cols is good. For fewer, adjust.\n",
    "    num_cols = 5\n",
    "    num_rows = (num_wrong_to_show + num_cols - 1) // num_cols\n",
    "\n",
    "    fig_wrong, axes_wrong = plt.subplots(num_rows, num_cols, figsize=(num_cols * 2, num_rows * 2.5))\n",
    "    axes_wrong = axes_wrong.flatten() # Flatten for easy iteration\n",
    "\n",
    "    print(f\"Found {len(wrong_indices)} wrong predictions. Displaying {num_wrong_to_show} of them.\")\n",
    "\n",
    "    for i, wrong_idx in enumerate(wrong_indices[:num_wrong_to_show]):\n",
    "        img = all_test_images[wrong_idx].squeeze().numpy()\n",
    "        true_label = final_true_labels[wrong_idx]\n",
    "        predicted_label = final_pred_labels[wrong_idx]\n",
    "\n",
    "        axes_wrong[i].imshow(img, cmap='gray')\n",
    "        axes_wrong[i].set_title(f\"True: {true_label}\\nPred: {predicted_label}\", color='red')\n",
    "        axes_wrong[i].axis('off')\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes_wrong)):\n",
    "        fig_wrong.delaxes(axes_wrong[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Misclassified Digits\", y=1.02, fontsize=16) # Add a main title\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52873c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "# Fixed: use 'lambda', close the parenthesis, and convert map to list for display\n",
    "result = list(map(lambda x, y: x + y, [1, 2, 3], [1, 2, 3]))\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
